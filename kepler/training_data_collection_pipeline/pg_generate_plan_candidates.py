# coding=utf-8
# Copyright 2022 Google LLC.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Library for generating explain plans for query templates + parameters.

Provides functionality for generating additional plans from pg configs.

```
Typical usage:

# query_metadata contains query info and list of params.
configs = ['enable_nestloop', 'enable_hashjoin']
results = distribute_get_query_plans(database, query_metadata, configs)
```
"""
import dataclasses
import functools
import itertools
import multiprocessing
from typing import Any, Callable, Dict, List, Iterable, Optional, Sequence, Tuple

import numpy as np

from kepler.training_data_collection_pipeline import pg_perturb_plan_cardinalities
from kepler.training_data_collection_pipeline import pg_plan_hint_extractor
from kepler.training_data_collection_pipeline import query_plan_utils
from kepler.training_data_collection_pipeline import query_utils


_ALL_SCAN_CONFIGS = frozenset(["enable_indexscan", "enable_indexonlyscan",
                               "enable_seqscan"])
_ALL_JOIN_CONFIGS = frozenset(["enable_hashjoin", "enable_mergejoin",
                               "enable_nestloop"])

JSON = Any


def _nonempty_powerset(iterable: Iterable[Any]) -> Iterable[Any]:
  """Computes nonempty elements of powerset of an iterable.

  Example: [1,2,3] --> (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)

  Args:
    iterable: Any iterable (collection, iterator, etc.).

  Returns:
    Iterable consisting of nonempty elements of powerset.
  """
  s = list(iterable)
  return itertools.chain.from_iterable(
      itertools.combinations(s, r) for r in range(1,
                                                  len(s) + 1))


def _is_valid_config_set(config_set: List[str]) -> bool:
  """Checks that config set isn't disabling all scans and/or all joins.

  In PG, we typically consider only three joins and three scans. Here,
  we check that neither set of three is fully disabled.

  Args:
    config_set: List of PG optimizer flags to be set to false.

  Returns:
    Boolean corresponding to whether the config set is valid or not.
  """
  config_set_as_set = set(config_set)
  return (not _ALL_SCAN_CONFIGS.issubset(config_set_as_set) and
          not _ALL_JOIN_CONFIGS.issubset(config_set_as_set))


def _get_additional_query_plans(
    query_manager: query_utils.QueryManager, query: str, configs: List[str],
    params: Sequence[str]) -> Tuple[List[JSON], List[str]]:
  """Iterate through power set of config params and generate corresponding plans.

  Args:
    query_manager: QueryManager object.
    query: SQL query template string with 0 or more parameters provided in the
      form of @param#, starting with 0.
    configs: List of Postgres optimizer configuration parameters.
    params: List of parameter values to substitute into the query. All values
      will be cast to str.

  Returns:
    Tuple consisting of:
      1. List of plans in JSON format that were generated by toggling off strict
         subsets of Postgres configuration parameters.
      2. List of additional config sets generated.
  """
  additional_plans = []
  config_sets = []
  # Skip empty config set since it corresponds to the default plan.
  for config_set in _nonempty_powerset(configs):
    if not _is_valid_config_set(config_set):
      continue
    additional_plans.append(
        query_manager.get_query_plan(query, params, config_set))
    config_sets.append(config_set)

  return additional_plans, config_sets


def get_query_plans(params: Sequence[str],
                    *,
                    database_configuration: query_utils.DatabaseConfiguration,
                    query: Optional[str] = None,
                    configs: Optional[List[str]] = None,
                    keys_to_remove: Optional[Sequence[str]] = None) -> JSON:
  """Gets explain plans for default plan as well as plans generated from config params.

  Works on a single set of parameter values.

  Args:
    params: List of parameter binding values.
    database_configuration: The configuration describing the database
      connection.
    query: Query in string format.
    configs: List of additional PG optimizer config params to use.
    keys_to_remove: Keys to remove from each plan.

  Returns:
    Dict mapping:
      params: Parameter values.
      result: Explain plan of default plan.
      additional_plans: List containing additional explain plans.
      sources: List of config param subsets mapping to the additional
        plans.
  """
  if not query:
    raise ValueError("Query must be specified.")
  query_manager = query_utils.QueryManager(database_configuration)

  if configs is None:
    configs = []

  additional_plans, config_sets = _get_additional_query_plans(
      query_manager, query, configs, params)

  if keys_to_remove:
    filter_func = functools.partial(
        query_plan_utils.filter_keys, keys_to_remove=keys_to_remove)
  else:
    filter_func = lambda x: x

  return {
      "params": params,
      "result": filter_func(query_manager.get_query_plan(query, params)),
      "additional_plans": list(map(filter_func, additional_plans)),
      "sources": config_sets
  }


def _get_row_hints_string(row_counts):
  """Creates row hint string from row counts dict.

  Args:
    row_counts: Dict mapping string of space-separated tables to desired row
      count.

  Returns:
    String corresponding to row hints in pg_hint_plan format, with
      hints in order of joined tables.
  """
  row_hints = [
      f"Rows({tables} #{row_counts[tables]})" for tables in sorted(row_counts)
  ]
  return " ".join(["/*+"] + row_hints + ["*/"])


def _sort_table_keys(row_counts):
  """Sorts each row table hint key, since they are permutation-invariant."""

  def get_sorted_key(key):
    return " ".join(sorted(key.split()))

  return {get_sorted_key(k): v for k, v in row_counts.items()}


def get_row_count_candidates(row_count: int,
                             exponent_base: int,
                             exponent_range: int) -> np.ndarray:
  """Generate exponentially-spaced candidate perturbations around row count.

  See generate_by_row_num_evolution for more details and usage.

  Args:
    row_count: Estimated row count.
    exponent_base: Integer base of exponential row number perturbations.
    exponent_range: One-sided range of exponent perturbations. Number of unique
      perturbation candidates will always be 2 * this value + 1.

  Returns:
    Array of candidate perturbations.
  """
  # Set min_exponent so that lower end is 1.
  min_exponent = -1 * min(np.log(row_count) // np.log(exponent_base),
                          exponent_range)
  max_exponent = min_exponent + 2 * exponent_range
  candidates = row_count * np.power(float(exponent_base),
                                    np.arange(min_exponent,
                                              max_exponent + 1))
  candidates = np.array(list(map(lambda x: max(int(x), 1), candidates)))
  assert len(set(candidates)) == len(candidates)
  return candidates


@dataclasses.dataclass(frozen=True)
class EvolutionState:
  plan: JSON
  row_counts: JSON
  num_perturbs: JSON


def generate_by_row_num_evolution(
    params: Sequence[str],
    *,
    database_configuration: query_utils.DatabaseConfiguration,
    query: Optional[str] = None,
    max_plans: Optional[int] = None,
    num_generations: int = 3,
    num_mutations_per_plan: int = 25,
    exponent_base: int = 10,
    exponent_range: int = 3,
    max_plans_per_generation: int = 20,
    perturb_unit_only: bool = True,
    max_perturbs_per_join: Optional[int] = None,
    keys_to_remove: Optional[Sequence[str]] = None) -> JSON:
  """Starting from the default plan, generates new plans by altering row number estimates.

  Perturbs row counts by uniformly sampling from exponentially-spaced perturbed
  row counts. Let b be exponent_base, k be exponent_range, and c be the
  estimated row count. We construct a set of 2k + 1 candidate perturbations
  centered around c as c * [b^m, ..., b^(m + 2k)], where m is chosen so that
  int(b^m) is exactly 1 if log_b(c) < r.

  With these perturbed row counts, we then use pg_hint_plan row number
  correction hints to iteratively generate new plans.

  It is not important that Postgres respects these hints exactly.
  For example, it may alter the counts by some factor (e.g for parallel
  queries). The goal of this method is simply to generate a variety of plans
  by guiding the default optimizer towards different, and potentially
  unrealistic, parts of the plan space.

  We don't attempt to use any given plan as a base plan in more than one
  generation, assuming that num_mutations_per_plan is enough to discover
  the relevant perturbed plans from that plan.

  Args:
    params: List of parameter binding values.
    database_configuration: The configuration describing the database
      connection.
    query: Query in string format.
    max_plans: Stop evolution after this threshold is exceeded.
    num_generations: Number of generations to "evolve" current set of plans.
    num_mutations_per_plan: For each plan, how many random mutations to try.
    exponent_base: Integer base of exponential row number perturbations.
    exponent_range: One-sided range of exponent perturbations. Number of unique
      perturbation candidates will always be 2 * this value + 1.
    max_plans_per_generation: Max number of plans to mutate per generation.
    perturb_unit_only: Whether to perturb only row counts equal to one.
    max_perturbs_per_join: Limit on how many times a specific join can be
      perturbed.
    keys_to_remove: Keys to remove from each plan.

  Returns:
    Dict mapping:
      params: Parameter values.
      result: Explain plan of default plan.
      additional_plans: List containing generated explain plans.
      sources: List of row hints that produced each additional plan.
  """
  if not query:
    raise ValueError("Query must be specified.")
  query_manager = query_utils.QueryManager(database_configuration)

  default_hints, default_plan = pg_plan_hint_extractor.get_single_query_hints_with_plan(
      query_manager, query, params)
  candidate_states = [EvolutionState(default_plan, {}, {})]
  all_hints = {default_hints}

  sampled_row_hints = set()

  def perturb_row_counts(row_counts, num_perturbs):
    perturbed_counts = {}
    for joined_tables, row_count in row_counts.items():
      # The vast majority of row counts under default optimizer are 1.
      # TODO(b207027435): Remove perturb_unit_only if setting it to False is
      # experimentally better.
      if (max_perturbs_per_join is not None and
          num_perturbs.get(joined_tables, 0) >= max_perturbs_per_join):
        continue
      if row_count != 1 and perturb_unit_only:
        continue
      candidates = get_row_count_candidates(row_count, exponent_base,
                                            exponent_range)
      rand_count = np.random.choice(candidates)
      if rand_count != row_count:
        perturbed_counts[joined_tables] = rand_count
        num_perturbs[joined_tables] = num_perturbs.get(joined_tables, 0) + 1
    return perturbed_counts

  additional_plans = []
  sources = []
  debug_info = {
      "candidates_per_generation": [1]
  }
  for _ in range(num_generations):
    new_candidate_states = []

    # TODO(b207027435): Instead of sampling uniformly at random, we can
    # choose candidate plans using a more classic evolutionary criterion.
    num_candidate_states = min(len(candidate_states), max_plans_per_generation)
    candidate_idxs = np.random.choice(
        np.arange(len(candidate_states)), num_candidate_states, replace=False)

    for idx in candidate_idxs:
      parent_state = candidate_states[idx]
      row_counts = pg_plan_hint_extractor.extract_row_counts(
          parent_state.plan["Plan"])
      row_counts = _sort_table_keys(row_counts)
      for _ in range(num_mutations_per_plan):
        perturbed_counts = parent_state.row_counts.copy()
        new_num_perturbs = parent_state.num_perturbs.copy()
        new_perturbed_counts = perturb_row_counts(row_counts, new_num_perturbs)
        if not new_perturbed_counts:
          continue

        perturbed_counts.update(new_perturbed_counts)

        row_hints = _get_row_hints_string(perturbed_counts)
        if row_hints in sampled_row_hints:
          continue
        sampled_row_hints.add(row_hints)

        hinted_query = f"{row_hints} {query}"
        new_hints, new_plan = pg_plan_hint_extractor.get_single_query_hints_with_plan(
            query_manager, hinted_query, params)

        if new_hints not in all_hints:
          all_hints.add(new_hints)
          new_candidate_states.append(
              EvolutionState(new_plan, perturbed_counts, new_num_perturbs))
          additional_plans.append(new_plan)
          sources.append(row_hints)

    candidate_states = new_candidate_states
    debug_info["candidates_per_generation"].append(len(new_candidate_states))

    if max_plans is not None and len(all_hints) > max_plans:
      break

  if keys_to_remove:
    filter_func = functools.partial(
        query_plan_utils.filter_keys, keys_to_remove=keys_to_remove)
  else:
    filter_func = lambda x: x

  return {
      "params": params,
      "result": filter_func(default_plan),
      "additional_plans": list(map(filter_func, additional_plans)),
      "sources": sources,
      "debug_info": debug_info
  }


def _extract_query_plan_perturbations(
    query_plan_perturbations_output: JSON) -> Tuple[List[JSON], List[str]]:
  """Unpack the desired query plans from the multiplicatively_perturb_plan_cardinalities structure.

  Args:
    query_plan_perturbations_output: The query plans generated by perturbing
      cardinalities in the format returned by
      multiplicatively_perturb_plan_cardinalities.

  Returns:
    Tuple:
      1) All the query plan perturbations across all parameters flattened to a
         single list.
      2) A parallel list of sources describing the query plan.
  """

  query_plan_perturbations = []
  sources = []
  for param, results in query_plan_perturbations_output.items():
    # The results key has a list per hint and per iteration. In this usage,
    # there is exactly 1 hint and exactly 1 iteration.
    query_plans = results["results"][0][0]["explain_output_across_cardinality"]
    query_plan_perturbations.extend(query_plans)
    sources.extend([param] * len(query_plans))

  return query_plan_perturbations, sources


def generate_by_exhaustive_cardinality_perturbations(
    params: Sequence[str],
    *,
    database_configuration: query_utils.DatabaseConfiguration,
    query: Optional[str] = None,
    cardinality_multipliers: List[float],
    keys_to_remove: Optional[Sequence[str]] = None) -> JSON:
  """Generates query plans by methodically forcing row hints.

  We retrieve query plans exhaustively enumerating across a range of
  hypothetical cardinalities per JOIN.

  Args:
    params: List of parameter binding values.
    database_configuration: The configuration describing the database
      connection.
    query: Query in string format.
    cardinality_multipliers: Multipliers to adjust the cardinality estimate for
      each join.
    keys_to_remove: Keys to remove from each plan.

  Returns:
    Dict mapping:
      params: Parameter values.
      result: Explain plan of default plan.
      additional_plans: List containing generated explain plans.
      sources: List of row hints that produced each additional plan.
  """
  if not query:
    raise ValueError("Query must be specified.")
  query_manager = query_utils.QueryManager(database_configuration)

  # TODO(b/207027435): Consider deduping the set of plans with unique
  # cardinality estimate signatures from the parameters before calling
  # multiplicatively_perturb_plan_cardinalities to avoid repetitive work. There
  # is a risk that we will need to make adjustments due to long runtimes when
  # the number of joins and len(cardinality_multipliers) cause an exponential
  # explosion.
  #
  # The dummy query id and the empty hint allow constructing arguments in the
  # format multiplicatively_perturb_plan_cardinalities expects. We set
  # verify_hints_unchanged to False because we want
  # multiplicatively_perturb_plan_cardinalities to produce different plans in
  # this usage.
  dummy_query_id = "_dummy_query_id"
  query_plan_perturbations_output = pg_perturb_plan_cardinalities.multiplicatively_perturb_plan_cardinalities(
      query_manager=query_manager,
      query_id=dummy_query_id,
      templates={dummy_query_id: {
          "query": query
      }},
      parameter_values={dummy_query_id: [{
          "params": params,
          "plan_index": 0
      }]},
      plan_hints={dummy_query_id: [{
          "hints": "/*+ */"
      }]},
      cardinality_multipliers=cardinality_multipliers,
      verify_hints_unchanged=False,
      limit=None,
      keys_to_remove=keys_to_remove)

  additional_plans, sources = _extract_query_plan_perturbations(
      query_plan_perturbations_output[dummy_query_id])
  _, default_plan = pg_plan_hint_extractor.get_single_query_hints_with_plan(
      query_manager, query, params)

  if keys_to_remove:
    filter_func = functools.partial(
        query_plan_utils.filter_keys, keys_to_remove=keys_to_remove)
  else:
    filter_func = lambda x: x

  return {
      "params": params,
      "result": filter_func(default_plan),
      "additional_plans": list(map(filter_func, additional_plans)),
      "sources": sources
  }


def execute_plan_generation(
    function: Callable[..., Any],
    function_kwargs: Dict[str, Any],
    all_params: List[List[str]],
    plan_hint_extractor: pg_plan_hint_extractor.PlanHintExtractor,
    chunksize: int = 100,
    distributed: bool = True,
    soft_total_plans_limit: Optional[int] = None) -> None:
  """Executes plan generation for many parameter values.

  The generated plans are fed into the plan_hint_extractor to be deduplicated
  and indexed by params. Although the function does not have an explicit return
  value, the internal state of plan_hint_extractor will be mutated by this
  function.

  This will typically be called with a large number (e.g. 1e6) of parameter
  values. Since generating EXPLAIN plans is CPU bound, multiprocessing can
  provide a large speedup by setting distributed to True.

  Args:
    function: The plan candidate generation function to be called.
    function_kwargs: Dict of kwargs to above function.
    all_params: List of parameters.
    plan_hint_extractor: A PlanHintExtractor for plan deduplication and
      indexing.
    chunksize: How many parameters to process in each subprocess.
    distributed: True if subprocess should be used.
    soft_total_plans_limit: If set, generate up to this number of plans using
      function. Once at least this total number of plans has been generated,
      only generate default plans afterwards. Due to the fact that a param can
      generate multiple new plans, and the guaranteed generation of default
      plans, this threshold may be exceeded.
  """

  def is_limit_reached() -> bool:
    return (soft_total_plans_limit is not None and
            plan_hint_extractor.get_num_hints() >= soft_total_plans_limit)

  default_only = functools.partial(
      get_query_plans,
      database_configuration=function_kwargs.get("database_configuration"),
      query=function_kwargs.get("query"))

  if distributed:
    with multiprocessing.Pool() as pool:
      last_index = len(all_params) - 1
      for i, result in enumerate(
          pool.imap(
              functools.partial(function, **function_kwargs),
              all_params,
              chunksize=chunksize)):
        plan_hint_extractor.add_query_plans(result)
        if is_limit_reached():
          last_index = i
          break
      for result in pool.imap(
          default_only, all_params[last_index + 1:], chunksize=chunksize):
        plan_hint_extractor.add_query_plans(result)
  else:
    for params in all_params:
      if is_limit_reached():
        plan_hint_extractor.add_query_plans(default_only(params))
      else:
        plan_hint_extractor.add_query_plans(function(params, **function_kwargs))
