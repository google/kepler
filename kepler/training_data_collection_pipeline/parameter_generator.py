# coding=utf-8
# Copyright 2022 Google LLC.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Generates parameter bindings for provided SQL queries.

The ParameterGenerator generates plausible parameter bindings for a provided
query using data values found in the database. The goal is for each parameter
binding to result in at least one result for the provided query.

```Typical usage:
  template_item = <load from external source>
  generator = ParameterGenerator(<database connection parameters>)
  # Generates 100 parameter bindings for the template_item.
  generator.generate_parameters(count=100, template_item=template_item)
```
"""

import bisect
import collections
import dataclasses
import datetime
import logging
import random
from typing import Any, List, Dict, Tuple
import urllib.parse

from kepler.training_data_collection_pipeline import query_utils

JSON = Any

_DELTA_NUMERIC = 1
_DELTA_NUMERIC_NOOP = 0
_DELTA_DATE = datetime.timedelta(days=1)
_DELTA_DATE_NOOP = datetime.timedelta(days=0)


def _format_date(date_value: datetime.date) -> str:
  return date_value.strftime('%Y-%m-%d')


def _should_handle_as_date(column_name: str) -> bool:
  """Determines if a column is a date or timestamp.

  To reduce the number of similar distinct values, we cast all date or
  time-based columns to date when generating parameter values.

  The current implementation makes very strong assumptions about the type based
  on the column name. This can be improved in the future, including via schema
  reflection, when necessary.

  Args:
    column_name: The name of the column whose data type is being checked.

  Returns:
    True if the column should be handled as a date.
  """

  return 'date' in column_name


def _get_numeric_operator_adjustment(operator: str) -> int:
  """Provides the delta to ensure a value is in the range defined by operator.

  The SQL query to generate parameter values presumes equality to ensure that
  parameter value will yield a result. In the case of < and >, we add or
  subtract a delta to ensure the value will be included in the range.

  This adjustment to guarantee a result in the original query is required when
  the parameter value is at the min or max of the distinct values generated by
  the query for that column when considering *all* the predicates.

  Example:
    Table foo
     _x_|_y_
      1 | 1
      2 | 2
      1 | 3
      1 | 4

    Query: SELECT * FROM foo where x = 2 and y > 2.

    Although 2 is not the min or the max of column y, it *is* the max amongst
    all rows where x = 2. Therefore, we need to adjust the parameter binding for
    y from 2 to 1 to ensure we will capture the one matching row. This issue is
    less likely to arise when x = 1. In SELECT * FROM foo where x = 1 and y > 1,
    the row with 1 is excluded, but there are other matching rows to ensure we
    do not get an empty result. In this case, only a predicate of y > 4 results
    in an issue.

  Args:
    operator: The predicate operator.

  Returns:
    A delta to add to the value generated by the SQL query for this column. The
    addition identity is returned if the operator does not require a
    modification the potential parameter value to ensure a result.
  """
  if operator == '<':
    return _DELTA_NUMERIC

  if operator == '>':
    return -_DELTA_NUMERIC

  return _DELTA_NUMERIC_NOOP


def _is_less_than_variant(operator: str) -> bool:
  return operator in {'<', '<='}


def _is_greater_than_variant(operator: str) -> bool:
  return operator in {'>', '>='}


def _get_date_operator_adjustment(operator: str) -> datetime.timedelta:
  """Provides the delta to ensure a value is in the range defined by operator.

  See comments of _get_numeric_operator_adjustment for additional details.

  Args:
    operator: The predicate operator.

  Returns:
    A delta to add to the value generated by the SQL query for this column. The
    addition identity is returned if the operator does not require a
    modification the potential parameter value to ensure a result.
  """
  if operator == '<':
    return _DELTA_DATE

  if operator == '>':
    return -_DELTA_DATE

  return _DELTA_DATE_NOOP


def _check_range_predicate_invariant(predicates: List[JSON],
                                     predicate: JSON) -> None:
  """Verifies range predicate usage aligns with expected format.

  All BETWEEN-style range predicates should appear twice: first with a >/>=
  operator and second with a </<= operator.

  Args:
    predicates: List of all predicates.
    predicate: Predicate expected to have a BETWEEN-style usage implemented with
      >/< or >=/<=.
  """
  index = 0
  valid = False
  while index < len(predicates):
    candidate = predicates[index]
    if predicate['alias'] == candidate['alias'] and predicate[
        'column'] == candidate['column']:
      assert _is_greater_than_variant(candidate['operator'])
      index += 1
      break
    index += 1

  while index < len(predicates):
    candidate = predicates[index]
    if predicate['alias'] == candidate['alias'] and predicate[
        'column'] == candidate['column']:
      assert _is_less_than_variant(candidate['operator'])
      valid = True
      break
    index += 1

  assert valid, predicate


def _get_distinct_column_values(
    predicates: List[JSON], template: JSON,
    query_manager: query_utils.QueryManager) -> List[List[int]]:
  """Returns the distinct values contained in the requested columns.

  The current implementation presumes this function is only used for int-valued
  columns based on the current Stack queries. This function and callers may need
  to be adjusted if the query set changes.

  Args:
    predicates: List of columns for which retrieve distinct values.
    template: Query template to identify the table name from the alias.
    query_manager: QueryManager access to the desired database.

  Returns:
    A list of lists, each containing the sorted, distinct int values from each
    requested column in the same order as predicates.
  """

  distinct_values = []
  for predicate in predicates:
    table = None
    for line in template['query'].split('\n'):
      if ' as ' in line.lower():
        tokens = line.split(' as ')
        if predicate['alias'].lower() == tokens[1].lower().strip(',').strip():
          table = tokens[0].strip()

    assert table

    if _should_handle_as_date(predicate['column']):
      select_column = f"DATE({predicate['column']})"
    else:
      select_column = predicate['column']

    query = f"""SELECT DISTINCT {select_column} FROM {table}
                WHERE {predicate['column']} IS NOT NULL
                ORDER BY {select_column} ASC"""

    distinct_values.append([value[0] for value in query_manager.execute(query)])

  return distinct_values


def _filter_group_by(line: str) -> bool:
  """Remove the GROUP BY from the original query.

  Parameter generation SELECTs for different columns.

  Args:
    line: Line of SQL query text.

  Returns:
    True if the line does not contain group by.
  """
  return 'group by' not in line.lower()


def _filter_limit(line: str) -> bool:
  """Remove the LIMIT from the original query.

  The original query's output LIMIT is not relevant to how many parameters are
  being generated.

  Args:
    line: Line of SQL query text.

  Returns:
    True if the line does not contain limit.
  """
  return 'limit' not in line.lower()


def _filter_order_by(line: str) -> bool:
  """Remove the ORDER BY from the original query.

  The original query's output ordering is not relevant to how parameters are
  generated. The DESC and ASC directives for ORDER BY are sometimes found on a
  line by themselves.

  Args:
    line: Line of SQL query text.

  Returns:
    True if the line does not contain order by, or solitary desc/asc tokens.
  """
  test_line = line.lower().strip()
  return 'order by' not in test_line and test_line != 'desc' and test_line != 'ASC'


def _filter_parameter_predicates(line: str) -> bool:
  """Remove the predicates relating to the parameters from the original query.

  Parameter generation SELECTs for the parameter values that will be used in
  these predicates such that all other non-parameterized predicates will also be
  satisfied.

  Args:
    line: Line of SQL query text.

  Returns:
    True if the line contains a parameterized predicate.
  """
  return '@param' not in line


def _get_parameters_query(count: int, dry_run: bool,
                          template: JSON) -> Tuple[str, List[JSON], List[JSON]]:
  """Composes an SQL query to select potential parameter bindings.

  The template query text is rewritten into an SQL query that will select all
  potential parameter bindings such that the template query would return at
  least one result. The rewritten query also uses the database to uniformly
  sample n of these parameter bindings without replacement.

  There exists an edge condition for > and < predicates where a query may not
  actually produce a result. This occurs in rare cases because this approach
  only provides complete guarantees that a column will *equal* a proposed
  parameter binding.

  Args:
    count: The max number of parameter bindings to sample. If there are fewer
      distinct bindings available, they will all be returned by the provided
      query.
    dry_run: Overrides count to generate only one parameter that is *not* a
      uniform random sample.
    template: The query template containing SQL text and predicate metadata.

  Returns:
    A tuple containing:
      1) The SQL query to sample parameter bindings.
      2) A list of predicates operating on a single column and directly
        representing parameter bindings sampled by the query.
      3) A list of predicates that have BETWEEN-style ranges.
  """
  sql_lines = template['query'].split('\n')

  assert 'select' in sql_lines[0].lower()
  assert 'from' not in sql_lines[0].lower()

  # Without a SQL parser and SQL generator, we rely on direct text manipulation
  # to extract relevant portions of the query template SQL text and generate a
  # SQL query to select potential parameter bindings.
  sql_lines_filtered = filter(_filter_parameter_predicates, sql_lines)
  sql_lines_filtered = filter(_filter_group_by, sql_lines_filtered)
  sql_lines_filtered = filter(_filter_limit, sql_lines_filtered)
  sql_lines = list(filter(_filter_order_by, sql_lines_filtered))

  base_predicates = []
  base_predicate_identifiers = []
  range_predictates = []

  # Predicates are supported in two formats:
  # 1) Base predicates occur once, comparing with a single column with a single
  #    operator.
  # 2) BETWEEN-style range predicates, where a single column has two
  #    parameterized predicates using a >/>= and a </<= operator.
  #
  # Separate out base predicates, including the first occurrence in a
  # BETWEEN-style range predicate pair, and the other half of the BETWEEN-style
  # range predicate.
  for predicate in template['predicates']:
    identifier = f"{predicate['alias']}.{predicate['column']}"
    if identifier in base_predicate_identifiers:
      _check_range_predicate_invariant(template['predicates'], predicate)
      assert predicate not in range_predictates
      range_predictates.append(predicate)
    else:
      base_predicates.append(predicate)
      base_predicate_identifiers.append(identifier)

  base_predicate_column_elements = []
  for predicate in base_predicates:
    if _should_handle_as_date(predicate['column']):
      # This approach will cause problems for equality-type predicates if we
      # cast a TIMESTAMP to a DATE. The current queries only involve range
      # predicates when interacting with time-related columns. This can be
      # improved to handle the equality-type cases when necessary.
      assert (_is_less_than_variant(predicate['operator']) or
              _is_greater_than_variant(predicate['operator']))
      base_predicate_column_elements.append(
          f"DATE({predicate['alias']}.{predicate['column']})")
    else:
      base_predicate_column_elements.append(
          f"{predicate['alias']}.{predicate['column']}")

  base_predicate_columns = ','.join(base_predicate_column_elements)
  sql_lines[0] = f'SELECT {base_predicate_columns}'

  # Remove SELECTed columns if any exist between SELECT and FROM.
  while 'from' not in sql_lines[1].lower():
    del sql_lines[1]

  # Avoid NULL parameter values.
  for predicate in range_predictates:
    full_predicate = f"{predicate['alias']}.{predicate['column']}"
    sql_lines.append(f'AND {full_predicate} IS NOT NULL')

  for predicate in base_predicates:
    full_predicate = f"{predicate['alias']}.{predicate['column']}"
    sql_lines.append(f'AND {full_predicate} IS NOT NULL')
    if 'website_url' == predicate['column']:
      # See generate_parameters function comments regarding website_url.
      sql_lines.append(f"AND {full_predicate} <> ''")

  # A trailing AND may occur if the following predicate was removed by
  # _filter_parameter_predicates.
  if sql_lines[-1].lower().endswith(' and'):
    sql_lines[-1] = sql_lines[-1][:-4].strip()

  sql_lines.append(f'GROUP BY {base_predicate_columns} ')
  if dry_run:
    sql_lines.append('LIMIT 1')
  else:
    sql_lines.append('ORDER BY random()')
    sql_lines.append(f'LIMIT {count}')

  return '\n'.join(sql_lines) + ';', base_predicates, range_predictates


def _extract_url_domain(url: str) -> str:
  netloc = urllib.parse.urlparse(url).netloc
  try:
    return f"%{netloc[netloc.rindex('.')+1:]}"
  except ValueError:
    return '%'


@dataclasses.dataclass
class TemplateItem:
  """Holder to link a query id with its corresponding template."""
  query_id: str
  template: JSON


class ParameterGenerator:
  """Generates plausible parameters bindings for a query template.

  A parameter binding is considered plausible if it would the query template
  would produce at least one result with that binding.

  This class implementation makes several assumptions regarding the format and
  style of the queries from the Stack benchmark.
  """

  def __init__(self, database_configuration: query_utils.DatabaseConfiguration):
    self._database_configuration = database_configuration
    random.seed(self._database_configuration.seed)

  def generate_parameters(self,
                          count: int,
                          template_item: TemplateItem,
                          dry_run: bool = False) -> Dict[str, JSON]:
    """Generates parameter bindings for the provided template.

    The bindings are sampled without replacement from the space of parameter
    bindings which produce at least one result for the provided template query.

    The website_url field is given special handling to create domain-related
    regular expressions for query templates 15 and 16.

    Args:
      count: The max number of parameter bindings to generate.
      template_item: Holder describing the query template for which to generate
        parameters.
      dry_run: Overrides count to generate only one parameter that is *not* a
        uniform random sample.

    Returns:
      A self-describing dictionary identifying the template for which parameters
      were generated as well as the parameter binding values themselves.
    """
    parameters_query, base_predicates, range_predicates = _get_parameters_query(
        count, dry_run, template_item.template)

    # The generate_parameters functionality may be the run in parallel to issue
    # concurrent parameter generation queries from different threads or
    # processes. Creating a new local QueryManager for each offers a simple
    # alternative to connection pooling since this use-case involves relative
    # few but expensive queries to parallelize.
    manager = query_utils.QueryManager(self._database_configuration)
    range_predicate_distinct_values = _get_distinct_column_values(
        range_predicates, template_item.template, manager)

    rows = manager.execute(parameters_query)
    output_parameters = collections.defaultdict(lambda: {})

    def _process_as_range_predicate(current_range_predicate_index: int,
                                    current_predicate: JSON) -> bool:
      return (current_range_predicate_index < len(range_predicates) and
              current_predicate['alias']
              == range_predicates[current_range_predicate_index]['alias'] and
              current_predicate['column']
              == range_predicates[current_range_predicate_index]['column'])

    # Prepare candidate values once per relevant column to reuse for each row.
    candidate_values_list = []
    first_row = next(iter(rows))
    assert len(first_row) == len(base_predicates)
    range_predicate_index = 0

    for value, predicate in zip(first_row, base_predicates):
      if _process_as_range_predicate(range_predicate_index, predicate):
        if isinstance(value, datetime.date):
          delta = _DELTA_DATE
        else:
          delta = _DELTA_NUMERIC
          value = int(value)

        # Prepend and append values just below the min column value and just
        # above the max column value to ensure there is always at least one
        # candidate_value greater than and less than the base_predicate
        # value. The base_predicate value will be within [column_min,
        # column_max].
        candidate_values_temp = range_predicate_distinct_values[
            range_predicate_index]
        candidate_values_list.append([candidate_values_temp[0] - delta] +
                                     candidate_values_temp +
                                     [candidate_values_temp[-1] + delta])
        range_predicate_index += 1
    assert len(candidate_values_list) == len(range_predicates)

    params = []
    log_every = len(rows) // 10
    for row_idx, row in enumerate(rows):
      if log_every and row_idx % log_every == 0:
        logging.info('Processed %s rows for %s', row_idx,
                     template_item.query_id)

      while True:
        params_from_row = []
        range_predicate_index = 0
        assert len(row) == len(base_predicates)
        for value, predicate in zip(row, base_predicates):
          if _process_as_range_predicate(range_predicate_index, predicate):
            # Selecting the lower and upper bound from the distinct values in
            # the column with a range predicate reduces the skew in range size
            # introduced by outlier values. The lower bound and upper bound are
            # selected such that value is always included in the range.
            candidate_values = candidate_values_list[range_predicate_index]
            lower_bound_value = random.choice(
                candidate_values[:bisect.bisect_left(candidate_values, value)])
            upper_bound_value = random.choice(
                candidate_values[bisect.bisect_right(candidate_values, value):])

            if isinstance(lower_bound_value, datetime.date):
              params_from_row.append(_format_date(lower_bound_value))
              params_from_row.append(_format_date(upper_bound_value))
            else:
              params_from_row.append(lower_bound_value)
              params_from_row.append(upper_bound_value)

            range_predicate_index += 1
          elif 'website_url' == predicate['column']:
            # See generate_parameters function comments regarding website_url.
            params_from_row.append(_extract_url_domain(value))
          elif isinstance(value, datetime.date):
            params_from_row.append(
                _format_date(
                    value +
                    _get_date_operator_adjustment(predicate['operator'])))
          elif isinstance(value, str):
            params_from_row.append(value)
          else:
            params_from_row.append(
                value + _get_numeric_operator_adjustment(predicate['operator']))

        if params_from_row not in params:
          params.append(params_from_row)
          break

    entry = output_parameters[template_item.query_id]
    entry['query'] = template_item.template['query']
    entry['predicates'] = template_item.template['predicates']
    entry['params'] = params

    return output_parameters
